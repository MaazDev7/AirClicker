# ðŸ–ï¸ Finger Detection & Virtual Mouse Project

> _"What if your fingers could talk to your computer?"_  
> _What started as an experiment... turned into something magical._

## â¤ï¸ About This Project

This isn't just another hand-gesture project.  
This is **finger detection** reimagined â€” minimalistic, powerful, and accurate.  
Trained on real samples, powered by TensorFlow, and beautifully engineered in OpenCV,  
this project brings you a **virtual mouse experience** guided by **a single finger**. ðŸŽ¯

Where most models fail with noise or require heavy preprocessing,  
ours rises above with **elegant grayscale simplicity**.  
It's **fast**, **lightweight**, and **beautifully interpretable**.  
No clutter. No guessing. Just results. ðŸ§¬âœ¨

---

## ðŸš€ Features

- ðŸ§  Trained custom model with `.keras` format
- ðŸ“· Real-time **Virtual Mouse** using hand gestures
- ðŸ” Clean prediction pipeline from static images
- âš™ï¸ Super light preprocessing (grayscale-based, no complex thresholding)
- ðŸ“Š Model training results visualized
- ðŸ” Works offline, no internet dependency

---

## ðŸ“‚ Project Structure

```
ðŸ“ fingers_detection_model
	â””â”€â”€ (Generated model artifacts)
ðŸ“ fingers
	â”œâ”€â”€ train/
	â””â”€â”€ test/
ðŸ“„ fingers_detection.keras        â† Final trained model
ðŸ“„ model_training.ipynb          â† Notebook to train model
ðŸ“„ testing.ipynb                 â† Testing model on static images
ðŸ“„ virtual_mouse.py              â† Real-time finger detection & control
ðŸ“„ training_metrics.png          â† Accuracy/Loss graphs
```

---

## ðŸ§ª Try It Yourself

### ðŸ”§ Requirements

- Python 3.10
- OpenCV
- TensorFlow
- NumPy

Install them via:

```bash
pip install tensorflow opencv-python numpy
```

---

### ðŸ–¼ï¸ Test Static Images

Run this to see magic on sample images:

```bash
python testing.py
```

(Each image opens one at a time â€” press any key to continue.)

---

### ðŸ–±ï¸ Run Virtual Mouse (1-Finger Detection)

```bash
python virtual_mouse.py
```

Control your mouse using a **single finger** â€” tracked in real time from your webcam.

---

## ðŸ“ˆ Model Performance

![Training Metrics](model_metrices/training_metrics.png)

- Accuracy: âœ… Over 95%
- Binary Classification: 1 finger vs others
- Lightweight architecture, lightning fast âš¡

---

## ðŸ™ Why This Matters

In a world of overengineered solutions,  
this project is a **reminder** that simplicity wins.  
You don't need 3D sensors or deep pipelines â€”  
just intuition, code, and heart. â¤ï¸

---

## ðŸ’¡ Inspired By

- The joy of using hands to express
- The elegance of grayscale
- The belief that simple tools can feel like magic

---

## ðŸ“¬ Contact

> Made with ðŸ’” and Python by **Muhammad Maaz Khan**  
> _"Because sometimes, one finger says more than a thousand words."_

---

## ðŸŒŸ Star This Project

If this touched your heart or sparked your brain,  
**please consider starring ðŸŒŸ the repository.**

Letâ€™s make minimalistic AI shine together âœ¨
